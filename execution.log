Spark assembly has been built with Hive, including Datanucleus jars on classpath
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/11/07 00:28:26 INFO SparkContext: Running Spark version 1.3.0
15/11/07 00:28:26 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
15/11/07 00:28:26 WARN Utils: Your hostname, tuca resolves to a loopback address: 127.0.1.1; using 10.0.0.2 instead (on interface wlan0)
15/11/07 00:28:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
15/11/07 00:28:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/11/07 00:28:27 INFO SecurityManager: Changing view acls to: mjost
15/11/07 00:28:27 INFO SecurityManager: Changing modify acls to: mjost
15/11/07 00:28:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(mjost); users with modify permissions: Set(mjost)
15/11/07 00:28:27 INFO Slf4jLogger: Slf4jLogger started
15/11/07 00:28:27 INFO Remoting: Starting remoting
15/11/07 00:28:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.0.2:39034]
15/11/07 00:28:27 INFO Utils: Successfully started service 'sparkDriver' on port 39034.
15/11/07 00:28:27 INFO SparkEnv: Registering MapOutputTracker
15/11/07 00:28:27 INFO SparkEnv: Registering BlockManagerMaster
15/11/07 00:28:27 INFO DiskBlockManager: Created local directory at /tmp/spark-0b109ee8-4e1b-4ca3-98e5-a24e7cfe3073/blockmgr-f7a87fbc-6862-4bbb-ad37-5969b31a24f6
15/11/07 00:28:27 INFO MemoryStore: MemoryStore started with capacity 2.1 GB
15/11/07 00:28:27 INFO HttpFileServer: HTTP File server directory is /tmp/spark-c6f5de2c-13cc-4ad8-9a9a-f38640ae0615/httpd-b090910c-b5eb-4e55-82d2-cd2a53b5016d
15/11/07 00:28:27 INFO HttpServer: Starting HTTP Server
15/11/07 00:28:27 INFO Server: jetty-8.y.z-SNAPSHOT
15/11/07 00:28:27 INFO AbstractConnector: Started SocketConnector@0.0.0.0:39849
15/11/07 00:28:27 INFO Utils: Successfully started service 'HTTP file server' on port 39849.
15/11/07 00:28:27 INFO SparkEnv: Registering OutputCommitCoordinator
15/11/07 00:28:27 INFO Server: jetty-8.y.z-SNAPSHOT
15/11/07 00:28:27 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
15/11/07 00:28:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/11/07 00:28:27 INFO SparkUI: Started SparkUI at http://10.0.0.2:4040
15/11/07 00:28:27 INFO SparkContext: Added JAR file:/home/mjost/workspace/spark-example/./target/scala-2.10/spark-example_2.10-0.1.jar at http://10.0.0.2:39849/jars/spark-example_2.10-0.1.jar with timestamp 1446852507923
15/11/07 00:28:27 INFO Executor: Starting executor ID <driver> on host localhost
15/11/07 00:28:27 INFO AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@10.0.0.2:39034/user/HeartbeatReceiver
15/11/07 00:28:28 INFO NettyBlockTransferService: Server created on 48947
15/11/07 00:28:28 INFO BlockManagerMaster: Trying to register BlockManager
15/11/07 00:28:28 INFO BlockManagerMasterActor: Registering block manager localhost:48947 with 2.1 GB RAM, BlockManagerId(<driver>, localhost, 48947)
15/11/07 00:28:28 INFO BlockManagerMaster: Registered BlockManager
15/11/07 00:28:28 INFO MemoryStore: ensureFreeSpace(163873) called with curMem=0, maxMem=2223023063
15/11/07 00:28:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 160.0 KB, free 2.1 GB)
15/11/07 00:28:28 INFO MemoryStore: ensureFreeSpace(16794) called with curMem=163873, maxMem=2223023063
15/11/07 00:28:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.4 KB, free 2.1 GB)
15/11/07 00:28:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:48947 (size: 16.4 KB, free: 2.1 GB)
15/11/07 00:28:28 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
15/11/07 00:28:28 INFO SparkContext: Created broadcast 0 from textFile at Example.scala:22
15/11/07 00:28:28 INFO FileInputFormat: Total input paths to process : 1
15/11/07 00:28:28 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
15/11/07 00:28:28 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
15/11/07 00:28:28 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
15/11/07 00:28:28 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
15/11/07 00:28:28 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
15/11/07 00:28:29 INFO SparkContext: Starting job: saveAsTextFile at Example.scala:28
15/11/07 00:28:29 INFO DAGScheduler: Registering RDD 4 (keyBy at Example.scala:26)
15/11/07 00:28:29 INFO DAGScheduler: Got job 0 (saveAsTextFile at Example.scala:28) with 4 output partitions (allowLocal=false)
15/11/07 00:28:29 INFO DAGScheduler: Final stage: Stage 1(saveAsTextFile at Example.scala:28)
15/11/07 00:28:29 INFO DAGScheduler: Parents of final stage: List(Stage 0)
15/11/07 00:28:29 INFO DAGScheduler: Missing parents: List(Stage 0)
15/11/07 00:28:29 INFO DAGScheduler: Submitting Stage 0 (MapPartitionsRDD[4] at keyBy at Example.scala:26), which has no missing parents
15/11/07 00:28:29 INFO MemoryStore: ensureFreeSpace(3992) called with curMem=180667, maxMem=2223023063
15/11/07 00:28:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 2.1 GB)
15/11/07 00:28:29 INFO MemoryStore: ensureFreeSpace(2318) called with curMem=184659, maxMem=2223023063
15/11/07 00:28:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.1 GB)
15/11/07 00:28:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:48947 (size: 2.3 KB, free: 2.1 GB)
15/11/07 00:28:29 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
15/11/07 00:28:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:839
15/11/07 00:28:29 INFO DAGScheduler: Submitting 4 missing tasks from Stage 0 (MapPartitionsRDD[4] at keyBy at Example.scala:26)
15/11/07 00:28:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
15/11/07 00:28:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 12157 bytes)
15/11/07 00:28:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 12157 bytes)
15/11/07 00:28:29 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 12157 bytes)
15/11/07 00:28:29 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 12341 bytes)
15/11/07 00:28:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/11/07 00:28:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/11/07 00:28:29 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
15/11/07 00:28:29 INFO Executor: Fetching http://10.0.0.2:39849/jars/spark-example_2.10-0.1.jar with timestamp 1446852507923
15/11/07 00:28:29 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
15/11/07 00:28:29 INFO Utils: Fetching http://10.0.0.2:39849/jars/spark-example_2.10-0.1.jar to /tmp/spark-996aadd8-cf7d-4abb-83c0-5913cadbcab9/userFiles-d5927087-0ff1-4878-baf3-777022fa70a9/fetchFileTemp4398080406582584118.tmp
15/11/07 00:28:29 INFO Executor: Adding file:/tmp/spark-996aadd8-cf7d-4abb-83c0-5913cadbcab9/userFiles-d5927087-0ff1-4878-baf3-777022fa70a9/spark-example_2.10-0.1.jar to class loader
15/11/07 00:28:29 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:0+33554432
15/11/07 00:28:29 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3892314112+33554432
15/11/07 00:28:29 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1946157056+33554432
15/11/07 00:28:29 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5838471168+33554432
15/11/07 00:28:30 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:33554432+33554432
15/11/07 00:28:30 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1979711488+33554432
15/11/07 00:28:30 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3925868544+33554432
15/11/07 00:28:30 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5872025600+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3959422976+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2013265920+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:67108864+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5905580032+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3992977408+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2046820352+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:100663296+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5939134464+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:134217728+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2080374784+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4026531840+33554432
15/11/07 00:28:31 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5972688896+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:167772160+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4060086272+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2113929216+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6006243328+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4093640704+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:201326592+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2147483648+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6039797760+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4127195136+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:234881024+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6073352192+33554432
15/11/07 00:28:32 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2181038080+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4160749568+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:268435456+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6106906624+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2214592512+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4194304000+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:301989888+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2248146944+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6140461056+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4227858432+33554432
15/11/07 00:28:33 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:335544320+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6174015488+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2281701376+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4261412864+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:369098752+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6207569920+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2315255808+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4294967296+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:402653184+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6241124352+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2348810240+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4328521728+33554432
15/11/07 00:28:34 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:436207616+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6274678784+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2382364672+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4362076160+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6308233216+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:469762048+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2415919104+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4395630592+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6341787648+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:503316480+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2449473536+33554432
15/11/07 00:28:35 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4429185024+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6375342080+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:536870912+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4462739456+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2483027968+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:570425344+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6408896512+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4496293888+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2516582400+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:603979776+33554432
15/11/07 00:28:36 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6442450944+33554432
15/11/07 00:28:37 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4529848320+33554432
15/11/07 00:28:37 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2550136832+33554432
15/11/07 00:28:37 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:637534208+33554432
15/11/07 00:28:37 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6476005376+33554432
15/11/07 00:28:37 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4563402752+33554432
15/11/07 00:28:37 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6509559808+33554432
15/11/07 00:28:37 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4596957184+33554432
15/11/07 00:28:37 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2583691264+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:671088640+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6543114240+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4630511616+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2617245696+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6576668672+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:704643072+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4664066048+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2650800128+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6610223104+33554432
15/11/07 00:28:38 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:738197504+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4697620480+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6643777536+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2684354560+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:771751936+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4731174912+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6677331968+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2717908992+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:805306368+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4764729344+33554432
15/11/07 00:28:39 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2751463424+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6710886400+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:838860800+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4798283776+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2785017856+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6744440832+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:872415232+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2818572288+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4831838208+33554432
15/11/07 00:28:40 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6777995264+33554432
15/11/07 00:28:41 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2852126720+33554432
15/11/07 00:28:41 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:905969664+33554432
15/11/07 00:28:41 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4865392640+33554432
15/11/07 00:28:41 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6811549696+33554432
15/11/07 00:28:41 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2885681152+33554432
15/11/07 00:28:41 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:939524096+33554432
15/11/07 00:28:41 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4898947072+33554432
15/11/07 00:28:41 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6845104128+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2919235584+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:973078528+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6878658560+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4932501504+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2952790016+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1006632960+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6912212992+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4966055936+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:2986344448+33554432
15/11/07 00:28:42 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1040187392+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:4999610368+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6945767424+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3019898880+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1073741824+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5033164800+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:6979321856+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3053453312+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5066719232+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1107296256+33554432
15/11/07 00:28:43 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7012876288+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3087007744+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5100273664+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1140850688+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7046430720+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5133828096+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3120562176+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1174405120+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7079985152+33554432
15/11/07 00:28:44 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5167382528+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7113539584+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1207959552+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3154116608+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5200936960+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7147094016+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3187671040+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1241513984+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5234491392+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7180648448+33554432
15/11/07 00:28:45 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3221225472+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1275068416+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5268045824+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7214202880+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3254779904+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1308622848+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5301600256+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7247757312+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3288334336+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1342177280+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5335154688+33554432
15/11/07 00:28:46 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7281311744+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1375731712+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3321888768+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5368709120+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7314866176+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3355443200+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1409286144+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5402263552+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7348420608+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3388997632+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1442840576+33554432
15/11/07 00:28:47 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5435817984+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7381975040+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3422552064+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1476395008+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5469372416+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7415529472+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3456106496+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1509949440+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5502926848+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7449083904+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3489660928+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1543503872+33554432
15/11/07 00:28:48 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5536481280+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7482638336+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3523215360+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1577058304+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5570035712+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7516192768+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3556769792+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1610612736+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5603590144+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7549747200+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3590324224+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1644167168+33554432
15/11/07 00:28:49 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5637144576+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7583301632+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3623878656+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5670699008+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1677721600+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7616856064+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3657433088+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5704253440+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1711276032+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7650410496+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3690987520+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5737807872+33554432
15/11/07 00:28:50 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1744830464+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7683964928+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3724541952+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5771362304+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1778384896+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7717519360+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3758096384+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:5804916736+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1811939328+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7751073792+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3791650816+33554432
15/11/07 00:28:51 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1845493760+33554432
15/11/07 00:28:52 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:7784628224+7275076
15/11/07 00:28:52 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3825205248+33554432
15/11/07 00:28:52 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1879048192+33554432
15/11/07 00:28:52 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1935 bytes result sent to driver
15/11/07 00:28:52 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 23421 ms on localhost (1/4)
15/11/07 00:28:52 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:3858759680+33554432
15/11/07 00:28:52 INFO HadoopRDD: Input split: file:/home/mjost/workspace/spark-example/localhdfs/input/big.csv:1912602624+33554432
15/11/07 00:28:52 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1935 bytes result sent to driver
15/11/07 00:28:52 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 23557 ms on localhost (2/4)
15/11/07 00:28:53 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1935 bytes result sent to driver
15/11/07 00:28:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 23878 ms on localhost (3/4)
15/11/07 00:28:53 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1935 bytes result sent to driver
15/11/07 00:28:53 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 23932 ms on localhost (4/4)
15/11/07 00:28:53 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/11/07 00:28:53 INFO DAGScheduler: Stage 0 (keyBy at Example.scala:26) finished in 23.945 s
15/11/07 00:28:53 INFO DAGScheduler: looking for newly runnable stages
15/11/07 00:28:53 INFO DAGScheduler: running: Set()
15/11/07 00:28:53 INFO DAGScheduler: waiting: Set(Stage 1)
15/11/07 00:28:53 INFO DAGScheduler: failed: Set()
15/11/07 00:28:53 INFO DAGScheduler: Missing parents for Stage 1: List()
15/11/07 00:28:53 INFO DAGScheduler: Submitting Stage 1 (MapPartitionsRDD[8] at saveAsTextFile at Example.scala:28), which is now runnable
15/11/07 00:28:53 INFO MemoryStore: ensureFreeSpace(112912) called with curMem=186977, maxMem=2223023063
15/11/07 00:28:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 110.3 KB, free 2.1 GB)
15/11/07 00:28:53 INFO MemoryStore: ensureFreeSpace(50896) called with curMem=299889, maxMem=2223023063
15/11/07 00:28:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 49.7 KB, free 2.1 GB)
15/11/07 00:28:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:48947 (size: 49.7 KB, free: 2.1 GB)
15/11/07 00:28:53 INFO BlockManagerMaster: Updated info of block broadcast_2_piece0
15/11/07 00:28:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:839
15/11/07 00:28:53 INFO DAGScheduler: Submitting 4 missing tasks from Stage 1 (MapPartitionsRDD[8] at saveAsTextFile at Example.scala:28)
15/11/07 00:28:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
15/11/07 00:28:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4, localhost, PROCESS_LOCAL, 1119 bytes)
15/11/07 00:28:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 5, localhost, PROCESS_LOCAL, 1119 bytes)
15/11/07 00:28:53 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 6, localhost, PROCESS_LOCAL, 1119 bytes)
15/11/07 00:28:53 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 7, localhost, PROCESS_LOCAL, 1119 bytes)
15/11/07 00:28:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 5)
15/11/07 00:28:53 INFO Executor: Running task 2.0 in stage 1.0 (TID 6)
15/11/07 00:28:53 INFO Executor: Running task 3.0 in stage 1.0 (TID 7)
15/11/07 00:28:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
15/11/07 00:28:53 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
15/11/07 00:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
15/11/07 00:28:53 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
15/11/07 00:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
15/11/07 00:28:53 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
15/11/07 00:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/11/07 00:28:53 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
15/11/07 00:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/11/07 00:28:55 INFO FileOutputCommitter: Saved output of task 'attempt_201511070028_0001_m_000002_6' to file:/home/mjost/workspace/spark-example/localhdfs/output/_temporary/0/task_201511070028_0001_m_000002
15/11/07 00:28:55 INFO SparkHadoopWriter: attempt_201511070028_0001_m_000002_6: Committed
15/11/07 00:28:55 INFO FileOutputCommitter: Saved output of task 'attempt_201511070028_0001_m_000000_4' to file:/home/mjost/workspace/spark-example/localhdfs/output/_temporary/0/task_201511070028_0001_m_000000
15/11/07 00:28:55 INFO SparkHadoopWriter: attempt_201511070028_0001_m_000000_4: Committed
15/11/07 00:28:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 844 bytes result sent to driver
15/11/07 00:28:55 INFO FileOutputCommitter: Saved output of task 'attempt_201511070028_0001_m_000003_7' to file:/home/mjost/workspace/spark-example/localhdfs/output/_temporary/0/task_201511070028_0001_m_000003
15/11/07 00:28:55 INFO SparkHadoopWriter: attempt_201511070028_0001_m_000003_7: Committed
15/11/07 00:28:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 2292 ms on localhost (1/4)
15/11/07 00:28:55 INFO FileOutputCommitter: Saved output of task 'attempt_201511070028_0001_m_000001_5' to file:/home/mjost/workspace/spark-example/localhdfs/output/_temporary/0/task_201511070028_0001_m_000001
15/11/07 00:28:55 INFO SparkHadoopWriter: attempt_201511070028_0001_m_000001_5: Committed
15/11/07 00:28:55 INFO Executor: Finished task 3.0 in stage 1.0 (TID 7). 844 bytes result sent to driver
15/11/07 00:28:55 INFO Executor: Finished task 2.0 in stage 1.0 (TID 6). 844 bytes result sent to driver
15/11/07 00:28:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 5). 844 bytes result sent to driver
15/11/07 00:28:55 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 7) in 2299 ms on localhost (2/4)
15/11/07 00:28:55 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 6) in 2304 ms on localhost (3/4)
15/11/07 00:28:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 5) in 2309 ms on localhost (4/4)
15/11/07 00:28:55 INFO DAGScheduler: Stage 1 (saveAsTextFile at Example.scala:28) finished in 2.314 s
15/11/07 00:28:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/11/07 00:28:55 INFO DAGScheduler: Job 0 finished: saveAsTextFile at Example.scala:28, took 26.461682 s
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
b68df5906cb0ddf61cafe44a4ed81a4290a63e31
